#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æŠ–éŸ³ä¸‹è½½å™¨ - ç»Ÿä¸€å¢å¼ºç‰ˆ
æ”¯æŒè§†é¢‘ã€å›¾æ–‡ã€ç”¨æˆ·ä¸»é¡µã€åˆé›†ç­‰å¤šç§å†…å®¹çš„æ‰¹é‡ä¸‹è½½
"""

import asyncio
import json
import logging
import os
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from urllib.parse import urlparse
import argparse
import yaml

# ç¬¬ä¸‰æ–¹åº“
try:
    import aiohttp
    import requests
    from rich.console import Console
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeRemainingColumn
    from rich.table import Table
    from rich.panel import Panel
    from rich.live import Live
    from rich import print as rprint
except ImportError as e:
    print(f"è¯·å®‰è£…å¿…è¦çš„ä¾èµ–: pip install aiohttp requests rich pyyaml")
    sys.exit(1)

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from apiproxy.douyin import douyin_headers
from apiproxy.douyin.urls import Urls
from apiproxy.douyin.result import Result
from apiproxy.common.utils import Utils
from apiproxy.douyin.auth.cookie_manager import AutoCookieManager
from apiproxy.douyin.database import DataBase

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('downloader.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Rich console
console = Console()


class ContentType:
    """å†…å®¹ç±»å‹æšä¸¾"""
    VIDEO = "video"
    IMAGE = "image" 
    USER = "user"
    MIX = "mix"
    MUSIC = "music"
    LIVE = "live"


class DownloadStats:
    """ä¸‹è½½ç»Ÿè®¡"""
    def __init__(self):
        self.total = 0
        self.success = 0
        self.failed = 0
        self.skipped = 0
        self.start_time = time.time()
    
    @property
    def success_rate(self):
        return (self.success / self.total * 100) if self.total > 0 else 0
    
    @property
    def elapsed_time(self):
        return time.time() - self.start_time
    
    def to_dict(self):
        return {
            'total': self.total,
            'success': self.success,
            'failed': self.failed,
            'skipped': self.skipped,
            'success_rate': f"{self.success_rate:.1f}%",
            'elapsed_time': f"{self.elapsed_time:.1f}s"
        }


class RateLimiter:
    """é€Ÿç‡é™åˆ¶å™¨"""
    def __init__(self, max_per_second: float = 2):
        self.max_per_second = max_per_second
        self.min_interval = 1.0 / max_per_second
        self.last_request = 0
    
    async def acquire(self):
        """è·å–è®¸å¯"""
        current = time.time()
        time_since_last = current - self.last_request
        if time_since_last < self.min_interval:
            await asyncio.sleep(self.min_interval - time_since_last)
        self.last_request = time.time()


class RetryManager:
    """é‡è¯•ç®¡ç†å™¨"""
    def __init__(self, max_retries: int = 3):
        self.max_retries = max_retries
        self.retry_delays = [1, 2, 5]  # é‡è¯•å»¶è¿Ÿ
    
    async def execute_with_retry(self, func, *args, **kwargs):
        """æ‰§è¡Œå‡½æ•°å¹¶è‡ªåŠ¨é‡è¯•"""
        last_error = None
        for attempt in range(self.max_retries):
            try:
                return await func(*args, **kwargs)
            except Exception as e:
                last_error = e
                if attempt < self.max_retries - 1:
                    delay = self.retry_delays[min(attempt, len(self.retry_delays) - 1)]
                    logger.warning(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}, {delay}ç§’åé‡è¯•...")
                    await asyncio.sleep(delay)
        raise last_error


class UnifiedDownloader:
    """ç»Ÿä¸€ä¸‹è½½å™¨"""
    
    def __init__(self, config_path: str = "config.yml"):
        self.config = self._load_config(config_path)
        self.urls_helper = Urls()
        self.result_helper = Result()
        self.utils = Utils()
        
        # ç»„ä»¶åˆå§‹åŒ–
        self.stats = DownloadStats()
        self.rate_limiter = RateLimiter(max_per_second=2)
        self.retry_manager = RetryManager(max_retries=self.config.get('retry_times', 3))
        
        # Cookieä¸è¯·æ±‚å¤´ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œæ”¯æŒè‡ªåŠ¨è·å–ï¼‰
        self.cookies = self.config.get('cookies') if 'cookies' in self.config else self.config.get('cookie')
        self.auto_cookie = bool(self.config.get('auto_cookie')) or (isinstance(self.config.get('cookie'), str) and self.config.get('cookie') == 'auto') or (isinstance(self.config.get('cookies'), str) and self.config.get('cookies') == 'auto')
        self.headers = {**douyin_headers}
        # é¿å…æœåŠ¡ç«¯ä½¿ç”¨brotliå¯¼è‡´aiohttpæ— æ³•è§£å‹ï¼ˆæœªå®‰è£…brotliåº“æ—¶ä¼šå‡ºç°ç©ºå“åº”ï¼‰
        self.headers['accept-encoding'] = 'gzip, deflate'
        # å¢é‡ä¸‹è½½ä¸æ•°æ®åº“
        self.increase_cfg: Dict[str, Any] = self.config.get('increase', {}) or {}
        self.enable_database: bool = bool(self.config.get('database', True))
        self.db: Optional[DataBase] = DataBase() if self.enable_database else None
        
        # ä¿å­˜è·¯å¾„
        self.save_path = Path(self.config.get('path', './Downloaded'))
        self.save_path.mkdir(parents=True, exist_ok=True)
        
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(config_path):
            # å…¼å®¹é…ç½®æ–‡ä»¶å‘½åï¼šä¼˜å…ˆ config.ymlï¼Œå…¶æ¬¡ config_simple.yml
            alt_path = 'config_simple.yml'
            if os.path.exists(alt_path):
                config_path = alt_path
            else:
                # è¿”å›ä¸€ä¸ªç©ºé…ç½®ï¼Œç”±å‘½ä»¤è¡Œå‚æ•°å†³å®š
                return {}
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # ç®€åŒ–é…ç½®å…¼å®¹ï¼šlinks/link, output_dir/path, cookie/cookies
        if 'links' in config and 'link' not in config:
            config['link'] = config['links']
        if 'output_dir' in config and 'path' not in config:
            config['path'] = config['output_dir']
        if 'cookie' in config and 'cookies' not in config:
            config['cookies'] = config['cookie']
        if isinstance(config.get('cookies'), str) and config.get('cookies') == 'auto':
            config['auto_cookie'] = True
        
        # å…è®¸æ—  linkï¼ˆé€šè¿‡å‘½ä»¤è¡Œä¼ å…¥ï¼‰
        # å¦‚æœä¸¤è€…éƒ½æ²¡æœ‰ï¼Œåç»­ä¼šåœ¨è¿è¡Œæ—¶æç¤º
        
        return config
    
    def _build_cookie_string(self) -> str:
        """æ„å»ºCookieå­—ç¬¦ä¸²"""
        if isinstance(self.cookies, str):
            return self.cookies
        elif isinstance(self.cookies, dict):
            return '; '.join([f'{k}={v}' for k, v in self.cookies.items()])
        elif isinstance(self.cookies, list):
            # æ”¯æŒæ¥è‡ªAutoCookieManagerçš„cookiesåˆ—è¡¨
            try:
                kv = {c.get('name'): c.get('value') for c in self.cookies if c.get('name') and c.get('value')}
                return '; '.join([f'{k}={v}' for k, v in kv.items()])
            except Exception:
                return ''
        return ''

    async def _initialize_cookies_and_headers(self):
        """åˆå§‹åŒ–Cookieä¸è¯·æ±‚å¤´ï¼ˆæ”¯æŒè‡ªåŠ¨è·å–ï¼‰"""
        # è‹¥é…ç½®ä¸ºå­—ç¬¦ä¸² 'auto'ï¼Œè§†ä¸ºæœªæä¾›ï¼Œè§¦å‘è‡ªåŠ¨è·å–
        if isinstance(self.cookies, str) and self.cookies.strip().lower() == 'auto':
            self.cookies = None
        
        # è‹¥å·²æ˜¾å¼æä¾›cookiesï¼Œåˆ™ç›´æ¥ä½¿ç”¨
        cookie_str = self._build_cookie_string()
        if cookie_str:
            self.headers['Cookie'] = cookie_str
            # åŒæ—¶è®¾ç½®åˆ°å…¨å±€ douyin_headersï¼Œç¡®ä¿æ‰€æœ‰ API è¯·æ±‚éƒ½èƒ½ä½¿ç”¨
            from apiproxy.douyin import douyin_headers
            douyin_headers['Cookie'] = cookie_str
            return
        
        # è‡ªåŠ¨è·å–Cookie
        if self.auto_cookie:
            try:
                console.print("[cyan]ğŸ” æ­£åœ¨è‡ªåŠ¨è·å–Cookie...[/cyan]")
                async with AutoCookieManager(cookie_file='cookies.pkl', headless=False) as cm:
                    cookies_list = await cm.get_cookies()
                    if cookies_list:
                        self.cookies = cookies_list
                        cookie_str = self._build_cookie_string()
                        if cookie_str:
                            self.headers['Cookie'] = cookie_str
                            # åŒæ—¶è®¾ç½®åˆ°å…¨å±€ douyin_headersï¼Œç¡®ä¿æ‰€æœ‰ API è¯·æ±‚éƒ½èƒ½ä½¿ç”¨
                            from apiproxy.douyin import douyin_headers
                            douyin_headers['Cookie'] = cookie_str
                            console.print("[green]âœ… Cookieè·å–æˆåŠŸ[/green]")
                            return
                console.print("[yellow]âš ï¸ è‡ªåŠ¨è·å–Cookieå¤±è´¥æˆ–ä¸ºç©ºï¼Œç»§ç»­å°è¯•æ— Cookieæ¨¡å¼[/yellow]")
            except Exception as e:
                logger.warning(f"è‡ªåŠ¨è·å–Cookieå¤±è´¥: {e}")
                console.print("[yellow]âš ï¸ è‡ªåŠ¨è·å–Cookieå¤±è´¥ï¼Œç»§ç»­å°è¯•æ— Cookieæ¨¡å¼[/yellow]")
        
        # æœªèƒ½è·å–Cookieåˆ™ä¸è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤headers
    
    def detect_content_type(self, url: str) -> ContentType:
        """æ£€æµ‹URLå†…å®¹ç±»å‹ï¼ˆåº”åœ¨çŸ­é“¾æ¥è§£æåè°ƒç”¨ï¼‰"""
        if '/user/' in url or '/share/user/' in url:
            return ContentType.USER
        elif '/video/' in url:
            return ContentType.VIDEO
        elif '/note/' in url:
            return ContentType.IMAGE
        elif '/collection/' in url or '/mix/' in url:
            return ContentType.MIX
        elif '/music/' in url:
            return ContentType.MUSIC
        elif 'live.douyin.com' in url:
            return ContentType.LIVE
        elif 'v.douyin.com' in url:
            return ContentType.VIDEO  # çŸ­é“¾æ¥æœªè§£ææ—¶çš„å›é€€
        else:
            return ContentType.VIDEO  # é»˜è®¤å½“ä½œè§†é¢‘
    
    async def resolve_short_url(self, url: str) -> str:
        """è§£æçŸ­é“¾æ¥"""
        if 'v.douyin.com' in url:
            try:
                # ä½¿ç”¨åŒæ­¥è¯·æ±‚è·å–é‡å®šå‘
                response = requests.get(url, headers=self.headers, allow_redirects=True, timeout=10)
                final_url = response.url
                logger.info(f"è§£æçŸ­é“¾æ¥: {url} -> {final_url}")
                return final_url
            except Exception as e:
                logger.warning(f"è§£æçŸ­é“¾æ¥å¤±è´¥: {e}")
        return url
    
    def extract_id_from_url(self, url: str, content_type: ContentType = None) -> Optional[str]:
        """ä»URLæå–ID
        
        Args:
            url: è¦è§£æçš„URL
            content_type: å†…å®¹ç±»å‹ï¼ˆå¯é€‰ï¼Œç”¨äºæŒ‡å¯¼æå–ï¼‰
        """
        # å¦‚æœå·²çŸ¥æ˜¯ç”¨æˆ·é¡µé¢ï¼Œç›´æ¥æå–ç”¨æˆ·ID
        if content_type == ContentType.USER or '/user/' in url:
            user_patterns = [
                r'/user/([\w-]+)',
                r'sec_uid=([\w-]+)'
            ]
            
            for pattern in user_patterns:
                match = re.search(pattern, url)
                if match:
                    user_id = match.group(1)
                    logger.info(f"æå–åˆ°ç”¨æˆ·ID: {user_id}")
                    return user_id
        
        # è§†é¢‘IDæ¨¡å¼ï¼ˆä¼˜å…ˆï¼‰
        video_patterns = [
            r'/video/(\d+)',
            r'/note/(\d+)',
            r'modal_id=(\d+)',
            r'aweme_id=(\d+)',
            r'item_id=(\d+)'
        ]
        
        for pattern in video_patterns:
            match = re.search(pattern, url)
            if match:
                video_id = match.group(1)
                logger.info(f"æå–åˆ°è§†é¢‘ID: {video_id}")
                return video_id
        
        # å…¶ä»–æ¨¡å¼
        other_patterns = [
            r'/collection/(\d+)',
            r'/music/(\d+)'
        ]
        
        for pattern in other_patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        # å°è¯•ä»URLä¸­æå–æ•°å­—ID
        number_match = re.search(r'(\d{15,20})', url)
        if number_match:
            video_id = number_match.group(1)
            logger.info(f"ä»URLæå–åˆ°æ•°å­—ID: {video_id}")
            return video_id
        
        logger.error(f"æ— æ³•ä»URLæå–ID: {url}")
        return None

    def _get_aweme_id_from_info(self, info: Dict) -> Optional[str]:
        """ä» aweme ä¿¡æ¯ä¸­æå– aweme_id"""
        try:
            if 'aweme_id' in info:
                return str(info.get('aweme_id'))
            # aweme_detail ç»“æ„
            return str(info.get('aweme', {}).get('aweme_id') or info.get('aweme_id'))
        except Exception:
            return None

    def _get_sec_uid_from_info(self, info: Dict) -> Optional[str]:
        """ä» aweme ä¿¡æ¯ä¸­æå–ä½œè€… sec_uid"""
        try:
            return info.get('author', {}).get('sec_uid')
        except Exception:
            return None

    def _should_skip_increment(self, context: str, info: Dict, mix_id: Optional[str] = None, music_id: Optional[str] = None, sec_uid: Optional[str] = None) -> bool:
        """æ ¹æ®å¢é‡é…ç½®ä¸æ•°æ®åº“è®°å½•åˆ¤æ–­æ˜¯å¦è·³è¿‡ä¸‹è½½"""
        if not self.db:
            return False
        aweme_id = self._get_aweme_id_from_info(info)
        if not aweme_id:
            return False

        try:
            if context == 'post' and self.increase_cfg.get('post', False):
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                return bool(self.db.get_user_post(sec, int(aweme_id)) if aweme_id.isdigit() else None)
            if context == 'like' and self.increase_cfg.get('like', False):
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                return bool(self.db.get_user_like(sec, int(aweme_id)) if aweme_id.isdigit() else None)
            if context == 'mix' and self.increase_cfg.get('mix', False):
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                mid = mix_id or ''
                return bool(self.db.get_mix(sec, mid, int(aweme_id)) if aweme_id.isdigit() else None)
            if context == 'music' and self.increase_cfg.get('music', False):
                mid = music_id or ''
                return bool(self.db.get_music(mid, int(aweme_id)) if aweme_id.isdigit() else None)
        except Exception:
            return False
        return False

    def _record_increment(self, context: str, info: Dict, mix_id: Optional[str] = None, music_id: Optional[str] = None, sec_uid: Optional[str] = None):
        """ä¸‹è½½æˆåŠŸåå†™å…¥æ•°æ®åº“è®°å½•"""
        if not self.db:
            return
        aweme_id = self._get_aweme_id_from_info(info)
        if not aweme_id or not aweme_id.isdigit():
            return
        try:
            if context == 'post':
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                self.db.insert_user_post(sec, int(aweme_id), info)
            elif context == 'like':
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                self.db.insert_user_like(sec, int(aweme_id), info)
            elif context == 'mix':
                sec = sec_uid or self._get_sec_uid_from_info(info) or ''
                mid = mix_id or ''
                self.db.insert_mix(sec, mid, int(aweme_id), info)
            elif context == 'music':
                mid = music_id or ''
                self.db.insert_music(mid, int(aweme_id), info)
        except Exception:
            pass
    
    async def download_single_video(self, url: str, progress=None) -> bool:
        """ä¸‹è½½å•ä¸ªè§†é¢‘/å›¾æ–‡"""
        try:
            # è§£æçŸ­é“¾æ¥
            url = await self.resolve_short_url(url)

            # è§£æåé‡æ–°æ£€æµ‹ç±»å‹ï¼ŒçŸ­é“¾æ¥å¯èƒ½æŒ‡å‘ç”¨æˆ·ä¸»é¡µ
            resolved_type = self.detect_content_type(url)
            if resolved_type == ContentType.USER:
                logger.info(f"çŸ­é“¾æ¥å®é™…æŒ‡å‘ç”¨æˆ·ä¸»é¡µï¼Œè½¬ä¸ºç”¨æˆ·ä¸‹è½½: {url}")
                return await self.download_user_page(url)

            # æå–ID
            video_id = self.extract_id_from_url(url, ContentType.VIDEO)
            if not video_id:
                logger.error(f"æ— æ³•ä»URLæå–ID: {url}")
                return False
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°è§†é¢‘IDï¼Œå°è¯•ä½œä¸ºè§†é¢‘IDç›´æ¥ä½¿ç”¨
            if not video_id and '/user/' not in url:
                # å¯èƒ½çŸ­é“¾æ¥ç›´æ¥åŒ…å«äº†è§†é¢‘ID
                video_id = url.split('/')[-2] if url.endswith('/') else url.split('/')[-1]
                logger.info(f"å°è¯•ä»çŸ­é“¾æ¥è·¯å¾„æå–ID: {video_id}")
            
            if not video_id:
                logger.error(f"æ— æ³•ä»URLæå–è§†é¢‘ID: {url}")
                return False
            
            # é™é€Ÿ
            await self.rate_limiter.acquire()
            
            # è·å–è§†é¢‘ä¿¡æ¯
            if progress:
                progress.update(task_id=progress.task_ids[-1], description="è·å–è§†é¢‘ä¿¡æ¯...")
            
            video_info = await self.retry_manager.execute_with_retry(
                self._fetch_video_info, video_id
            )
            
            if not video_info:
                logger.error(f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {video_id}")
                self.stats.failed += 1
                return False
            
            # ä¸‹è½½è§†é¢‘æ–‡ä»¶
            if progress:
                progress.update(task_id=progress.task_ids[-1], description="ä¸‹è½½è§†é¢‘æ–‡ä»¶...")
            
            success = await self._download_media_files(video_info, progress)
            
            if success:
                self.stats.success += 1
                logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {url}")
            else:
                self.stats.failed += 1
                logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {url}")
            
            return success
            
        except Exception as e:
            logger.error(f"ä¸‹è½½è§†é¢‘å¼‚å¸¸ {url}: {e}")
            self.stats.failed += 1
            return False
        finally:
            self.stats.total += 1
    
    async def _fetch_video_info(self, video_id: str) -> Optional[Dict]:
        """è·å–è§†é¢‘ä¿¡æ¯"""
        try:
            # ä½¿ç”¨ Douyin ç±»
            from apiproxy.douyin.douyin import Douyin
            
            # åˆ›å»º Douyin å®ä¾‹
            dy = Douyin(database=False)
            
            # è®¾ç½®æˆ‘ä»¬çš„ cookies åˆ° douyin_headers
            if hasattr(self, 'cookies') and self.cookies:
                cookie_str = self._build_cookie_string()
                if cookie_str:
                    from apiproxy.douyin import douyin_headers
                    douyin_headers['Cookie'] = cookie_str
                    logger.info(f"è®¾ç½® Cookie åˆ° Douyin ç±»: {cookie_str[:100]}...")
            
            try:
                # ä½¿ç”¨ç°æœ‰çš„æˆåŠŸå®ç°
                result = dy.getAwemeInfo(video_id)
                if result:
                    logger.info(f"Douyin ç±»æˆåŠŸè·å–è§†é¢‘ä¿¡æ¯: {result.get('desc', '')[:30]}")
                    return result
                else:
                    logger.error("Douyin ç±»è¿”å›ç©ºç»“æœ")
                    
            except Exception as e:
                logger.error(f"Douyin ç±»è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
                
        except Exception as e:
            logger.error(f"å¯¼å…¥æˆ–ä½¿ç”¨ Douyin ç±»å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # å¦‚æœ Douyin ç±»å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ¥å£ï¼ˆiesdouyinï¼Œæ— éœ€X-Bogusï¼‰
        try:
            fallback_url = f"https://www.iesdouyin.com/web/api/v2/aweme/iteminfo/?item_ids={video_id}"
            logger.info(f"å°è¯•å¤‡ç”¨æ¥å£è·å–è§†é¢‘ä¿¡æ¯: {fallback_url}")
            
            # è®¾ç½®æ›´é€šç”¨çš„è¯·æ±‚å¤´
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Referer': 'https://www.douyin.com/',
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(fallback_url, headers=headers, timeout=15) as response:
                    logger.info(f"å¤‡ç”¨æ¥å£å“åº”çŠ¶æ€: {response.status}")
                    if response.status != 200:
                        logger.error(f"å¤‡ç”¨æ¥å£è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
                    
                    text = await response.text()
                    logger.info(f"å¤‡ç”¨æ¥å£å“åº”å†…å®¹é•¿åº¦: {len(text)}")
                    
                    if not text:
                        logger.error("å¤‡ç”¨æ¥å£å“åº”ä¸ºç©º")
                        return None
                    
                    try:
                        data = json.loads(text)
                        logger.info(f"å¤‡ç”¨æ¥å£è¿”å›æ•°æ®: {data}")
                        
                        item_list = (data or {}).get('item_list') or []
                        if item_list:
                            aweme_detail = item_list[0]
                            logger.info("å¤‡ç”¨æ¥å£æˆåŠŸè·å–è§†é¢‘ä¿¡æ¯")
                            return aweme_detail
                        else:
                            logger.error("å¤‡ç”¨æ¥å£è¿”å›çš„æ•°æ®ä¸­æ²¡æœ‰ item_list")
                            
                    except json.JSONDecodeError as e:
                        logger.error(f"å¤‡ç”¨æ¥å£JSONè§£æå¤±è´¥: {e}")
                        logger.error(f"åŸå§‹å“åº”å†…å®¹: {text}")
                        return None
                        
        except Exception as e:
            logger.error(f"å¤‡ç”¨æ¥å£è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        
        return None
    
    def _build_detail_params(self, aweme_id: str) -> str:
        """æ„å»ºè¯¦æƒ…APIå‚æ•°"""
        # ä½¿ç”¨ä¸ç°æœ‰ douyinapi.py ç›¸åŒçš„å‚æ•°æ ¼å¼
        params = [
            f'aweme_id={aweme_id}',
            'device_platform=webapp',
            'aid=6383'
        ]
        return '&'.join(params)
    
    async def _download_media_files(self, video_info: Dict, progress=None) -> bool:
        """ä¸‹è½½åª’ä½“æ–‡ä»¶"""
        try:
            # åˆ¤æ–­ç±»å‹
            is_image = bool(video_info.get('images'))
            
            # æ„å»ºä¿å­˜è·¯å¾„
            author_name = video_info.get('author', {}).get('nickname', 'unknown')
            desc = video_info.get('desc', '')[:50].replace('/', '_')
            # å…¼å®¹ create_time ä¸ºæ—¶é—´æˆ³æˆ–æ ¼å¼åŒ–å­—ç¬¦ä¸²
            raw_create_time = video_info.get('create_time')
            dt_obj = None
            if isinstance(raw_create_time, (int, float)):
                dt_obj = datetime.fromtimestamp(raw_create_time)
            elif isinstance(raw_create_time, str) and raw_create_time:
                for fmt in ('%Y-%m-%d %H.%M.%S', '%Y-%m-%d_%H-%M-%S', '%Y-%m-%d %H:%M:%S'):
                    try:
                        dt_obj = datetime.strptime(raw_create_time, fmt)
                        break
                    except Exception:
                        pass
            if dt_obj is None:
                dt_obj = datetime.fromtimestamp(time.time())
            create_time = dt_obj.strftime('%Y-%m-%d_%H-%M-%S')
            
            folder_name = f"{create_time}_{desc}" if desc else create_time
            save_dir = self.save_path / author_name / folder_name
            save_dir.mkdir(parents=True, exist_ok=True)
            
            success = True
            
            if is_image:
                # ä¸‹è½½å›¾æ–‡ï¼ˆæ— æ°´å°ï¼‰
                images = video_info.get('images', [])
                for i, img in enumerate(images):
                    url_list = img.get('url_list', [])
                    img_url = self._get_best_quality_url(url_list)
                    if img_url:
                        file_path = save_dir / f"image_{i+1}.jpg"
                        if await self._download_file(img_url, file_path, fallback_urls=url_list):
                            logger.info(f"ä¸‹è½½å›¾ç‰‡ {i+1}/{len(images)}: {file_path.name}")
                        else:
                            success = False
                        await asyncio.sleep(0.3)  # é¿å…è¯·æ±‚è¿‡å¿«è¢«é™æµ
            else:
                # ä¸‹è½½è§†é¢‘ï¼ˆæ— æ°´å°ï¼‰
                video_url = self._get_no_watermark_url(video_info)
                if video_url:
                    # æ”¶é›†æ‰€æœ‰å¯ç”¨çš„è§†é¢‘URLä½œä¸ºå¤‡é€‰
                    video_fallbacks = []
                    for key in ('play_addr', 'play_addr_h264', 'download_addr'):
                        addr = video_info.get('video', {}).get(key)
                        if addr and addr.get('url_list'):
                            video_fallbacks.extend(addr['url_list'])
                    file_path = save_dir / f"{folder_name}.mp4"
                    if await self._download_file(video_url, file_path, fallback_urls=video_fallbacks):
                        logger.info(f"ä¸‹è½½è§†é¢‘: {file_path.name}")
                    else:
                        success = False

                # ä¸‹è½½éŸ³é¢‘
                if self.config.get('music', True):
                    music_url = self._get_music_url(video_info)
                    if music_url:
                        file_path = save_dir / f"{folder_name}_music.mp3"
                        await self._download_file(music_url, file_path)
            
            # ä¸‹è½½å°é¢
            if self.config.get('cover', True):
                cover_urls = video_info.get('video', {}).get('cover', {}).get('url_list', [])
                cover_url = self._get_cover_url(video_info)
                if cover_url:
                    file_path = save_dir / f"{folder_name}_cover.jpg"
                    await self._download_file(cover_url, file_path, fallback_urls=cover_urls)
            
            # ä¿å­˜JSONæ•°æ®
            if self.config.get('json', True):
                json_path = save_dir / f"{folder_name}_data.json"
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(video_info, f, ensure_ascii=False, indent=2)
            
            return success
            
        except Exception as e:
            logger.error(f"ä¸‹è½½åª’ä½“æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def _get_no_watermark_url(self, video_info: Dict) -> Optional[str]:
        """è·å–æ— æ°´å°è§†é¢‘URL"""
        try:
            # ä¼˜å…ˆä½¿ç”¨play_addr_h264
            play_addr = video_info.get('video', {}).get('play_addr_h264') or \
                       video_info.get('video', {}).get('play_addr')
            
            if play_addr:
                url_list = play_addr.get('url_list', [])
                if url_list:
                    # æ›¿æ¢URLä»¥è·å–æ— æ°´å°ç‰ˆæœ¬
                    url = url_list[0]
                    url = url.replace('playwm', 'play')
                    url = url.replace('720p', '1080p')
                    return url
            
            # å¤‡ç”¨ï¼šdownload_addr
            download_addr = video_info.get('video', {}).get('download_addr')
            if download_addr:
                url_list = download_addr.get('url_list', [])
                if url_list:
                    return url_list[0]
                    
        except Exception as e:
            logger.error(f"è·å–æ— æ°´å°URLå¤±è´¥: {e}")
        
        return None
    
    def _get_best_quality_url(self, url_list: List[str]) -> Optional[str]:
        """è·å–æœ€é«˜è´¨é‡çš„URL"""
        if not url_list:
            return None
        
        # ä¼˜å…ˆé€‰æ‹©åŒ…å«ç‰¹å®šå…³é”®è¯çš„URL
        for keyword in ['1080', 'origin', 'high']:
            for url in url_list:
                if keyword in url:
                    return url
        
        # è¿”å›ç¬¬ä¸€ä¸ª
        return url_list[0]
    
    def _get_music_url(self, video_info: Dict) -> Optional[str]:
        """è·å–éŸ³ä¹URL"""
        try:
            music = video_info.get('music', {})
            play_url = music.get('play_url', {})
            url_list = play_url.get('url_list', [])
            return url_list[0] if url_list else None
        except:
            return None
    
    def _get_cover_url(self, video_info: Dict) -> Optional[str]:
        """è·å–å°é¢URL"""
        try:
            cover = video_info.get('video', {}).get('cover', {})
            url_list = cover.get('url_list', [])
            return self._get_best_quality_url(url_list)
        except:
            return None
    
    async def _download_file(self, url: str, save_path: Path, fallback_urls: List[str] = None) -> bool:
        """ä¸‹è½½æ–‡ä»¶ï¼Œæ”¯æŒå¤‡é€‰URLé‡è¯•"""
        try:
            if save_path.exists():
                logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {save_path.name}")
                return True

            # æ„å»ºå€™é€‰URLåˆ—è¡¨ï¼šä¸»URL + å¤‡é€‰URL
            urls_to_try = [url]
            if fallback_urls:
                urls_to_try.extend(u for u in fallback_urls if u != url)

            # ä¸‹è½½ç”¨çš„headerså»æ‰refererï¼Œéƒ¨åˆ†CDNä¼šæ‹¦æˆª
            dl_headers = {k: v for k, v in self.headers.items() if k.lower() != 'referer'}

            async with aiohttp.ClientSession() as session:
                for try_url in urls_to_try:
                    try:
                        async with session.get(try_url, headers=dl_headers) as response:
                            if response.status == 200:
                                content = await response.read()
                                with open(save_path, 'wb') as f:
                                    f.write(content)
                                return True
                            elif response.status == 403 and try_url != urls_to_try[-1]:
                                logger.warning(f"ä¸‹è½½è¿”å›403ï¼Œå°è¯•å¤‡é€‰URL")
                                await asyncio.sleep(0.5)
                                continue
                            else:
                                logger.error(f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                    except Exception as e:
                        logger.warning(f"ä¸‹è½½å¼‚å¸¸: {e}")
                        if try_url != urls_to_try[-1]:
                            continue

            return False

        except Exception as e:
            logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥ {url}: {e}")
            return False
    
    async def download_user_page(self, url: str) -> bool:
        """ä¸‹è½½ç”¨æˆ·ä¸»é¡µå†…å®¹"""
        try:
            # æå–ç”¨æˆ·ID
            user_id = self.extract_id_from_url(url, ContentType.USER)
            if not user_id:
                logger.error(f"æ— æ³•ä»URLæå–ç”¨æˆ·ID: {url}")
                return False
            
            console.print(f"\n[cyan]æ­£åœ¨è·å–ç”¨æˆ· {user_id} çš„ä½œå“åˆ—è¡¨...[/cyan]")
            
            # æ ¹æ®é…ç½®ä¸‹è½½ä¸åŒç±»å‹çš„å†…å®¹
            mode = self.config.get('mode', ['post'])
            if isinstance(mode, str):
                mode = [mode]
            
            # å¢åŠ æ€»ä»»åŠ¡æ•°ç»Ÿè®¡
            total_posts = 0
            if 'post' in mode:
                total_posts += self.config.get('number', {}).get('post', 0) or 1
            if 'like' in mode:
                total_posts += self.config.get('number', {}).get('like', 0) or 1
            if 'mix' in mode:
                total_posts += self.config.get('number', {}).get('allmix', 0) or 1
            
            self.stats.total += total_posts
            
            for m in mode:
                if m == 'post':
                    await self._download_user_posts(user_id)
                elif m == 'like':
                    await self._download_user_likes(user_id)
                elif m == 'mix':
                    await self._download_user_mixes(user_id)
            
            return True
            
        except Exception as e:
            logger.error(f"ä¸‹è½½ç”¨æˆ·ä¸»é¡µå¤±è´¥: {e}")
            return False
    
    async def _download_user_posts(self, user_id: str):
        """ä¸‹è½½ç”¨æˆ·å‘å¸ƒçš„ä½œå“"""
        max_count = self.config.get('number', {}).get('post', 0)
        cursor = 0
        downloaded = 0
        
        console.print(f"\n[green]å¼€å§‹ä¸‹è½½ç”¨æˆ·å‘å¸ƒçš„ä½œå“...[/green]")

        # å…ˆè·å–å…¨éƒ¨ä½œå“å¹¶æ‰“å°ç½‘é¡µURL
        all_posts = await self._fetch_user_posts(user_id, 0)
        if all_posts:
            aweme_all = all_posts.get('aweme_list', [])
            if aweme_all:
                console.print(f"\n[cyan]ğŸ“‹ ç”¨æˆ·ä½œå“ç½‘é¡µåœ°å€ï¼ˆå…± {len(aweme_all)} ä¸ªï¼‰:[/cyan]")
                for idx, aweme in enumerate(aweme_all, 1):
                    aid = aweme.get('aweme_id', '')
                    atype = aweme.get('awemeType', 0)
                    desc = aweme.get('desc', '')[:30]
                    if atype == 1:
                        web_url = f"https://www.douyin.com/note/{aid}"
                    else:
                        web_url = f"https://www.douyin.com/video/{aid}"
                    console.print(f"  {idx:>3}. {web_url}  [dim]{desc}[/dim]")
                console.print()

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeRemainingColumn(),
            console=console
        ) as progress:

            while True:
                # é™é€Ÿ
                await self.rate_limiter.acquire()

                # å¤ç”¨å·²è·å–çš„æ•°æ®ï¼Œé¿å…é‡å¤è¯·æ±‚
                if all_posts and cursor == 0:
                    posts_data = all_posts
                    all_posts = None  # åªç”¨ä¸€æ¬¡
                else:
                    posts_data = await self._fetch_user_posts(user_id, cursor)
                if not posts_data:
                    break

                aweme_list = posts_data.get('aweme_list', [])
                if not aweme_list:
                    break

                # ä¸‹è½½ä½œå“
                for aweme in aweme_list:
                    if max_count > 0 and downloaded >= max_count:
                        console.print(f"[yellow]å·²è¾¾åˆ°ä¸‹è½½æ•°é‡é™åˆ¶: {max_count}[/yellow]")
                        return
                    
                    # æ—¶é—´è¿‡æ»¤
                    if not self._check_time_filter(aweme):
                        continue
                    
                    # åˆ›å»ºä¸‹è½½ä»»åŠ¡
                    task_id = progress.add_task(
                        f"ä¸‹è½½ä½œå“ {downloaded + 1}", 
                        total=100
                    )
                    
                    # å¢é‡åˆ¤æ–­
                    if self._should_skip_increment('post', aweme, sec_uid=user_id):
                        continue
                    
                    # ä¸‹è½½
                    success = await self._download_media_files(aweme, progress)
                    
                    if success:
                        downloaded += 1
                        self.stats.success += 1  # å¢åŠ æˆåŠŸè®¡æ•°
                        progress.update(task_id, completed=100)
                        self._record_increment('post', aweme, sec_uid=user_id)
                    else:
                        self.stats.failed += 1  # å¢åŠ å¤±è´¥è®¡æ•°
                        progress.update(task_id, description="[red]ä¸‹è½½å¤±è´¥[/red]")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤š
                if not posts_data.get('has_more'):
                    break
                
                cursor = posts_data.get('max_cursor', 0)
        
        console.print(f"[green]âœ… ç”¨æˆ·ä½œå“ä¸‹è½½å®Œæˆï¼Œå…±ä¸‹è½½ {downloaded} ä¸ª[/green]")
    
    async def _fetch_user_posts(self, user_id: str, cursor: int = 0) -> Optional[Dict]:
        """è·å–ç”¨æˆ·ä½œå“åˆ—è¡¨"""
        try:
            # ä½¿ç”¨ Douyin ç±»çš„ getUserInfo æ–¹æ³•
            from apiproxy.douyin.douyin import Douyin
            
            # åˆ›å»º Douyin å®ä¾‹
            dy = Douyin(database=False)
            
            # è·å–ç”¨æˆ·ä½œå“åˆ—è¡¨
            result = dy.getUserInfo(
                user_id, 
                "post", 
                35, 
                0,  # ä¸é™åˆ¶æ•°é‡
                False,  # ä¸å¯ç”¨å¢é‡
                "",  # start_time
                ""   # end_time
            )
            
            if result:
                logger.info(f"Douyin ç±»æˆåŠŸè·å–ç”¨æˆ·ä½œå“åˆ—è¡¨ï¼Œå…± {len(result)} ä¸ªä½œå“")
                # è½¬æ¢ä¸ºæœŸæœ›çš„æ ¼å¼
                return {
                    'status_code': 0,
                    'aweme_list': result,
                    'max_cursor': cursor,
                    'has_more': False
                }
            else:
                logger.error("Douyin ç±»è¿”å›ç©ºç»“æœ")
                return None
                
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä½œå“åˆ—è¡¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        return None
    
    async def _download_user_likes(self, user_id: str):
        """ä¸‹è½½ç”¨æˆ·å–œæ¬¢çš„ä½œå“"""
        max_count = 0
        try:
            max_count = int(self.config.get('number', {}).get('like', 0))
        except Exception:
            max_count = 0
        cursor = 0
        downloaded = 0

        console.print(f"\n[green]å¼€å§‹ä¸‹è½½ç”¨æˆ·å–œæ¬¢çš„ä½œå“...[/green]")

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeRemainingColumn(),
            console=console
        ) as progress:

            while True:
                # é™é€Ÿ
                await self.rate_limiter.acquire()

                # è·å–å–œæ¬¢åˆ—è¡¨
                likes_data = await self._fetch_user_likes(user_id, cursor)
                if not likes_data:
                    break

                aweme_list = likes_data.get('aweme_list', [])
                if not aweme_list:
                    break

                # ä¸‹è½½ä½œå“
                for aweme in aweme_list:
                    if max_count > 0 and downloaded >= max_count:
                        console.print(f"[yellow]å·²è¾¾åˆ°ä¸‹è½½æ•°é‡é™åˆ¶: {max_count}[/yellow]")
                        return

                    if not self._check_time_filter(aweme):
                        continue

                    task_id = progress.add_task(
                        f"ä¸‹è½½å–œæ¬¢ {downloaded + 1}",
                        total=100
                    )

                    # å¢é‡åˆ¤æ–­
                    if self._should_skip_increment('like', aweme, sec_uid=user_id):
                        continue

                    success = await self._download_media_files(aweme, progress)

                    if success:
                        downloaded += 1
                        progress.update(task_id, completed=100)
                        self._record_increment('like', aweme, sec_uid=user_id)
                    else:
                        progress.update(task_id, description="[red]ä¸‹è½½å¤±è´¥[/red]")

                # ç¿»é¡µ
                if not likes_data.get('has_more'):
                    break
                cursor = likes_data.get('max_cursor', 0)

        console.print(f"[green]âœ… å–œæ¬¢ä½œå“ä¸‹è½½å®Œæˆï¼Œå…±ä¸‹è½½ {downloaded} ä¸ª[/green]")

    async def _fetch_user_likes(self, user_id: str, cursor: int = 0) -> Optional[Dict]:
        """è·å–ç”¨æˆ·å–œæ¬¢çš„ä½œå“åˆ—è¡¨"""
        try:
            params_list = [
                f'sec_user_id={user_id}',
                f'max_cursor={cursor}',
                'count=35',
                'aid=6383',
                'device_platform=webapp',
                'channel=channel_pc_web',
                'pc_client_type=1',
                'version_code=170400',
                'version_name=17.4.0',
                'cookie_enabled=true',
                'screen_width=1920',
                'screen_height=1080',
                'browser_language=zh-CN',
                'browser_platform=MacIntel',
                'browser_name=Chrome',
                'browser_version=122.0.0.0',
                'browser_online=true'
            ]
            params = '&'.join(params_list)

            api_url = self.urls_helper.USER_FAVORITE_A

            try:
                xbogus = self.utils.getXbogus(params)
                full_url = f"{api_url}{params}&X-Bogus={xbogus}"
            except Exception as e:
                logger.warning(f"è·å–X-Boguså¤±è´¥: {e}, å°è¯•ä¸å¸¦X-Bogus")
                full_url = f"{api_url}{params}"

            logger.info(f"è¯·æ±‚ç”¨æˆ·å–œæ¬¢åˆ—è¡¨: {full_url[:100]}...")

            async with aiohttp.ClientSession() as session:
                async with session.get(full_url, headers=self.headers, timeout=10) as response:
                    if response.status != 200:
                        logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None

                    text = await response.text()
                    if not text:
                        logger.error("å“åº”å†…å®¹ä¸ºç©º")
                        return None

                    data = json.loads(text)
                    if data.get('status_code') == 0:
                        return data
                    else:
                        logger.error(f"APIè¿”å›é”™è¯¯: {data.get('status_msg', 'æœªçŸ¥é”™è¯¯')}")
                        return None
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·å–œæ¬¢åˆ—è¡¨å¤±è´¥: {e}")
        return None

    async def _download_user_mixes(self, user_id: str):
        """ä¸‹è½½ç”¨æˆ·çš„æ‰€æœ‰åˆé›†ï¼ˆæŒ‰é…ç½®å¯é™åˆ¶æ•°é‡ï¼‰"""
        max_allmix = 0
        try:
            # å…¼å®¹æ—§é”®å allmix æˆ– mix
            number_cfg = self.config.get('number', {}) or {}
            max_allmix = int(number_cfg.get('allmix', number_cfg.get('mix', 0)) or 0)
        except Exception:
            max_allmix = 0

        cursor = 0
        fetched = 0

        console.print(f"\n[green]å¼€å§‹è·å–ç”¨æˆ·åˆé›†åˆ—è¡¨...[/green]")
        while True:
            await self.rate_limiter.acquire()
            mix_list_data = await self._fetch_user_mix_list(user_id, cursor)
            if not mix_list_data:
                break

            mix_infos = mix_list_data.get('mix_infos') or []
            if not mix_infos:
                break

            for mix in mix_infos:
                if max_allmix > 0 and fetched >= max_allmix:
                    console.print(f"[yellow]å·²è¾¾åˆ°åˆé›†æ•°é‡é™åˆ¶: {max_allmix}[/yellow]")
                    return
                mix_id = mix.get('mix_id')
                mix_name = mix.get('mix_name', '')
                console.print(f"[cyan]ä¸‹è½½åˆé›†[/cyan]: {mix_name} ({mix_id})")
                await self._download_mix_by_id(mix_id)
                fetched += 1

            if not mix_list_data.get('has_more'):
                break
            cursor = mix_list_data.get('cursor', 0)

        console.print(f"[green]âœ… ç”¨æˆ·åˆé›†ä¸‹è½½å®Œæˆï¼Œå…±å¤„ç† {fetched} ä¸ª[/green]")

    async def _fetch_user_mix_list(self, user_id: str, cursor: int = 0) -> Optional[Dict]:
        """è·å–ç”¨æˆ·åˆé›†åˆ—è¡¨"""
        try:
            params_list = [
                f'sec_user_id={user_id}',
                f'cursor={cursor}',
                'count=35',
                'aid=6383',
                'device_platform=webapp',
                'channel=channel_pc_web',
                'pc_client_type=1',
                'version_code=170400',
                'version_name=17.4.0',
                'cookie_enabled=true',
                'screen_width=1920',
                'screen_height=1080',
                'browser_language=zh-CN',
                'browser_platform=MacIntel',
                'browser_name=Chrome',
                'browser_version=122.0.0.0',
                'browser_online=true'
            ]
            params = '&'.join(params_list)

            api_url = self.urls_helper.USER_MIX_LIST
            try:
                xbogus = self.utils.getXbogus(params)
                full_url = f"{api_url}{params}&X-Bogus={xbogus}"
            except Exception as e:
                logger.warning(f"è·å–X-Boguså¤±è´¥: {e}, å°è¯•ä¸å¸¦X-Bogus")
                full_url = f"{api_url}{params}"

            logger.info(f"è¯·æ±‚ç”¨æˆ·åˆé›†åˆ—è¡¨: {full_url[:100]}...")
            async with aiohttp.ClientSession() as session:
                async with session.get(full_url, headers=self.headers, timeout=10) as response:
                    if response.status != 200:
                        logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
                    text = await response.text()
                    if not text:
                        logger.error("å“åº”å†…å®¹ä¸ºç©º")
                        return None
                    data = json.loads(text)
                    if data.get('status_code') == 0:
                        return data
                    else:
                        logger.error(f"APIè¿”å›é”™è¯¯: {data.get('status_msg', 'æœªçŸ¥é”™è¯¯')}")
                        return None
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·åˆé›†åˆ—è¡¨å¤±è´¥: {e}")
        return None

    async def download_mix(self, url: str) -> bool:
        """æ ¹æ®åˆé›†é“¾æ¥ä¸‹è½½åˆé›†å†…æ‰€æœ‰ä½œå“"""
        try:
            mix_id = None
            for pattern in [r'/collection/(\d+)', r'/mix/detail/(\d+)']:
                m = re.search(pattern, url)
                if m:
                    mix_id = m.group(1)
                    break
            if not mix_id:
                logger.error(f"æ— æ³•ä»åˆé›†é“¾æ¥æå–ID: {url}")
                return False
            await self._download_mix_by_id(mix_id)
            return True
        except Exception as e:
            logger.error(f"ä¸‹è½½åˆé›†å¤±è´¥: {e}")
            return False

    async def _download_mix_by_id(self, mix_id: str):
        """æŒ‰åˆé›†IDä¸‹è½½å…¨éƒ¨ä½œå“"""
        cursor = 0
        downloaded = 0

        console.print(f"\n[green]å¼€å§‹ä¸‹è½½åˆé›† {mix_id} ...[/green]")

        while True:
            await self.rate_limiter.acquire()
            data = await self._fetch_mix_awemes(mix_id, cursor)
            if not data:
                break

            aweme_list = data.get('aweme_list') or []
            if not aweme_list:
                break

            for aweme in aweme_list:
                success = await self._download_media_files(aweme)
                if success:
                    downloaded += 1

            if not data.get('has_more'):
                break
            cursor = data.get('cursor', 0)

        console.print(f"[green]âœ… åˆé›†ä¸‹è½½å®Œæˆï¼Œå…±ä¸‹è½½ {downloaded} ä¸ª[/green]")

    async def _fetch_mix_awemes(self, mix_id: str, cursor: int = 0) -> Optional[Dict]:
        """è·å–åˆé›†ä¸‹ä½œå“åˆ—è¡¨"""
        try:
            params_list = [
                f'mix_id={mix_id}',
                f'cursor={cursor}',
                'count=35',
                'aid=6383',
                'device_platform=webapp',
                'channel=channel_pc_web',
                'pc_client_type=1',
                'version_code=170400',
                'version_name=17.4.0',
                'cookie_enabled=true',
                'screen_width=1920',
                'screen_height=1080',
                'browser_language=zh-CN',
                'browser_platform=MacIntel',
                'browser_name=Chrome',
                'browser_version=122.0.0.0',
                'browser_online=true'
            ]
            params = '&'.join(params_list)

            api_url = self.urls_helper.USER_MIX
            try:
                xbogus = self.utils.getXbogus(params)
                full_url = f"{api_url}{params}&X-Bogus={xbogus}"
            except Exception as e:
                logger.warning(f"è·å–X-Boguså¤±è´¥: {e}, å°è¯•ä¸å¸¦X-Bogus")
                full_url = f"{api_url}{params}"

            logger.info(f"è¯·æ±‚åˆé›†ä½œå“åˆ—è¡¨: {full_url[:100]}...")
            async with aiohttp.ClientSession() as session:
                async with session.get(full_url, headers=self.headers, timeout=10) as response:
                    if response.status != 200:
                        logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
                    text = await response.text()
                    if not text:
                        logger.error("å“åº”å†…å®¹ä¸ºç©º")
                        return None
                    data = json.loads(text)
                    # USER_MIX è¿”å›æ²¡æœ‰ç»Ÿä¸€çš„ status_codeï¼Œè¿™é‡Œç›´æ¥è¿”å›
                    return data
        except Exception as e:
            logger.error(f"è·å–åˆé›†ä½œå“å¤±è´¥: {e}")
        return None

    async def download_music(self, url: str) -> bool:
        """æ ¹æ®éŸ³ä¹é¡µé“¾æ¥ä¸‹è½½éŸ³ä¹ä¸‹çš„æ‰€æœ‰ä½œå“ï¼ˆæ”¯æŒå¢é‡ï¼‰"""
        try:
            # æå– music_id
            music_id = None
            m = re.search(r'/music/(\d+)', url)
            if m:
                music_id = m.group(1)
            if not music_id:
                logger.error(f"æ— æ³•ä»éŸ³ä¹é“¾æ¥æå–ID: {url}")
                return False

            cursor = 0
            downloaded = 0
            limit_num = 0
            try:
                limit_num = int((self.config.get('number', {}) or {}).get('music', 0))
            except Exception:
                limit_num = 0

            console.print(f"\n[green]å¼€å§‹ä¸‹è½½éŸ³ä¹ {music_id} ä¸‹çš„ä½œå“...[/green]")

            while True:
                await self.rate_limiter.acquire()
                data = await self._fetch_music_awemes(music_id, cursor)
                if not data:
                    break
                aweme_list = data.get('aweme_list') or []
                if not aweme_list:
                    break

                for aweme in aweme_list:
                    if limit_num > 0 and downloaded >= limit_num:
                        console.print(f"[yellow]å·²è¾¾åˆ°éŸ³ä¹ä¸‹è½½æ•°é‡é™åˆ¶: {limit_num}[/yellow]")
                        return True
                    if self._should_skip_increment('music', aweme, music_id=music_id):
                        continue
                    success = await self._download_media_files(aweme)
                    if success:
                        downloaded += 1
                        self._record_increment('music', aweme, music_id=music_id)

                if not data.get('has_more'):
                    break
                cursor = data.get('cursor', 0)

            console.print(f"[green]âœ… éŸ³ä¹ä½œå“ä¸‹è½½å®Œæˆï¼Œå…±ä¸‹è½½ {downloaded} ä¸ª[/green]")
            return True
        except Exception as e:
            logger.error(f"ä¸‹è½½éŸ³ä¹é¡µå¤±è´¥: {e}")
            return False

    async def _fetch_music_awemes(self, music_id: str, cursor: int = 0) -> Optional[Dict]:
        """è·å–éŸ³ä¹ä¸‹ä½œå“åˆ—è¡¨"""
        try:
            params_list = [
                f'music_id={music_id}',
                f'cursor={cursor}',
                'count=35',
                'aid=6383',
                'device_platform=webapp',
                'channel=channel_pc_web',
                'pc_client_type=1',
                'version_code=170400',
                'version_name=17.4.0',
                'cookie_enabled=true',
                'screen_width=1920',
                'screen_height=1080',
                'browser_language=zh-CN',
                'browser_platform=MacIntel',
                'browser_name=Chrome',
                'browser_version=122.0.0.0',
                'browser_online=true'
            ]
            params = '&'.join(params_list)

            api_url = self.urls_helper.MUSIC
            try:
                xbogus = self.utils.getXbogus(params)
                full_url = f"{api_url}{params}&X-Bogus={xbogus}"
            except Exception as e:
                logger.warning(f"è·å–X-Boguså¤±è´¥: {e}, å°è¯•ä¸å¸¦X-Bogus")
                full_url = f"{api_url}{params}"

            logger.info(f"è¯·æ±‚éŸ³ä¹ä½œå“åˆ—è¡¨: {full_url[:100]}...")
            async with aiohttp.ClientSession() as session:
                async with session.get(full_url, headers=self.headers, timeout=10) as response:
                    if response.status != 200:
                        logger.error(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return None
                    text = await response.text()
                    if not text:
                        logger.error("å“åº”å†…å®¹ä¸ºç©º")
                        return None
                    data = json.loads(text)
                    return data
        except Exception as e:
            logger.error(f"è·å–éŸ³ä¹ä½œå“å¤±è´¥: {e}")
        return None
    
    def _check_time_filter(self, aweme: Dict) -> bool:
        """æ£€æŸ¥æ—¶é—´è¿‡æ»¤"""
        start_time = self.config.get('start_time')
        end_time = self.config.get('end_time')
        
        if not start_time and not end_time:
            return True
        
        raw_create_time = aweme.get('create_time')
        if not raw_create_time:
            return True
        
        create_date = None
        if isinstance(raw_create_time, (int, float)):
            try:
                create_date = datetime.fromtimestamp(raw_create_time)
            except Exception:
                create_date = None
        elif isinstance(raw_create_time, str):
            for fmt in ('%Y-%m-%d %H.%M.%S', '%Y-%m-%d_%H-%M-%S', '%Y-%m-%d %H:%M:%S'):
                try:
                    create_date = datetime.strptime(raw_create_time, fmt)
                    break
                except Exception:
                    pass
        
        if create_date is None:
            return True
        
        if start_time:
            start_date = datetime.strptime(start_time, '%Y-%m-%d')
            if create_date < start_date:
                return False
        
        if end_time:
            end_date = datetime.strptime(end_time, '%Y-%m-%d')
            if create_date > end_date:
                return False
        
        return True
    
    async def run(self):
        """è¿è¡Œä¸‹è½½å™¨"""
        # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
        console.print(Panel.fit(
            "[bold cyan]æŠ–éŸ³ä¸‹è½½å™¨ v3.0 - ç»Ÿä¸€å¢å¼ºç‰ˆ[/bold cyan]\n"
            "[dim]æ”¯æŒè§†é¢‘ã€å›¾æ–‡ã€ç”¨æˆ·ä¸»é¡µã€åˆé›†æ‰¹é‡ä¸‹è½½[/dim]",
            border_style="cyan"
        ))
        
        # åˆå§‹åŒ–Cookieä¸è¯·æ±‚å¤´
        await self._initialize_cookies_and_headers()
        
        # è·å–URLåˆ—è¡¨
        urls = self.config.get('link', [])
        # å…¼å®¹ï¼šå•æ¡å­—ç¬¦ä¸²
        if isinstance(urls, str):
            urls = [urls]
        if not urls:
            console.print("[red]æ²¡æœ‰æ‰¾åˆ°è¦ä¸‹è½½çš„é“¾æ¥ï¼[/red]")
            return
        
        # è§£æçŸ­é“¾æ¥å¹¶åˆ†æURLç±»å‹
        console.print(f"\n[cyan]ğŸ“Š é“¾æ¥åˆ†æ[/cyan]")
        resolved_urls = []
        for url in urls:
            resolved = await self.resolve_short_url(url)
            content_type = self.detect_content_type(resolved)
            resolved_urls.append((resolved, content_type))
            console.print(f"  â€¢ {content_type.upper()}: {url[:50]}...")

        # å¼€å§‹ä¸‹è½½
        console.print(f"\n[green]â³ å¼€å§‹ä¸‹è½½ {len(resolved_urls)} ä¸ªé“¾æ¥...[/green]\n")

        for i, (url, content_type) in enumerate(resolved_urls, 1):
            console.print(f"[{i}/{len(resolved_urls)}] å¤„ç†: {url[:80]}")
            
            if content_type == ContentType.VIDEO or content_type == ContentType.IMAGE:
                await self.download_single_video(url)
            elif content_type == ContentType.USER:
                await self.download_user_page(url)
                # è‹¥é…ç½®åŒ…å« like æˆ– mixï¼Œé¡ºå¸¦å¤„ç†
                modes = self.config.get('mode', ['post'])
                if 'like' in modes:
                    user_id = self.extract_id_from_url(url, ContentType.USER)
                    if user_id:
                        await self._download_user_likes(user_id)
                if 'mix' in modes:
                    user_id = self.extract_id_from_url(url, ContentType.USER)
                    if user_id:
                        await self._download_user_mixes(user_id)
            elif content_type == ContentType.MIX:
                await self.download_mix(url)
            elif content_type == ContentType.MUSIC:
                await self.download_music(url)
            else:
                console.print(f"[yellow]ä¸æ”¯æŒçš„å†…å®¹ç±»å‹: {content_type}[/yellow]")
            
            # æ˜¾ç¤ºè¿›åº¦
            console.print(f"è¿›åº¦: {i}/{len(resolved_urls)} | æˆåŠŸ: {self.stats.success} | å¤±è´¥: {self.stats.failed}")
            console.print("-" * 60)
        
        # æ˜¾ç¤ºç»Ÿè®¡
        self._show_stats()
    
    def _show_stats(self):
        """æ˜¾ç¤ºä¸‹è½½ç»Ÿè®¡"""
        console.print("\n" + "=" * 60)
        
        # åˆ›å»ºç»Ÿè®¡è¡¨æ ¼
        table = Table(title="ğŸ“Š ä¸‹è½½ç»Ÿè®¡", show_header=True, header_style="bold magenta")
        table.add_column("é¡¹ç›®", style="cyan", width=12)
        table.add_column("æ•°å€¼", style="green")
        
        stats = self.stats.to_dict()
        table.add_row("æ€»ä»»åŠ¡æ•°", str(stats['total']))
        table.add_row("æˆåŠŸ", str(stats['success']))
        table.add_row("å¤±è´¥", str(stats['failed']))
        table.add_row("è·³è¿‡", str(stats['skipped']))
        table.add_row("æˆåŠŸç‡", stats['success_rate'])
        table.add_row("ç”¨æ—¶", stats['elapsed_time'])
        
        console.print(table)
        console.print("\n[bold green]âœ… ä¸‹è½½ä»»åŠ¡å®Œæˆï¼[/bold green]")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æŠ–éŸ³ä¸‹è½½å™¨ - ç»Ÿä¸€å¢å¼ºç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '-c', '--config',
        default='config.yml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.ymlï¼Œè‡ªåŠ¨å…¼å®¹ config_simple.yml)'
    )
    
    parser.add_argument(
        '-u', '--url',
        nargs='+',
        help='ç›´æ¥æŒ‡å®šè¦ä¸‹è½½çš„URL'
    )
    parser.add_argument(
        '-p', '--path',
        default=None,
        help='ä¿å­˜è·¯å¾„ (è¦†ç›–é…ç½®æ–‡ä»¶)'
    )
    parser.add_argument(
        '--auto-cookie',
        action='store_true',
        help='è‡ªåŠ¨è·å–Cookieï¼ˆéœ€è¦å·²å®‰è£…Playwrightï¼‰'
    )
    parser.add_argument(
        '--cookie',
        help='æ‰‹åŠ¨æŒ‡å®šCookieå­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "msToken=xxx; ttwid=yyy"'
    )
    
    args = parser.parse_args()
    
    # ç»„åˆé…ç½®æ¥æºï¼šä¼˜å…ˆå‘½ä»¤è¡Œ
    temp_config = {}
    if args.url:
        temp_config['link'] = args.url
    
    # è¦†ç›–ä¿å­˜è·¯å¾„
    if args.path:
        temp_config['path'] = args.path
    
    # Cookieé…ç½®
    if args.auto_cookie:
        temp_config['auto_cookie'] = True
        temp_config['cookies'] = 'auto'
    if args.cookie:
        temp_config['cookies'] = args.cookie
        temp_config['auto_cookie'] = False
    
    # å¦‚æœå­˜åœ¨ä¸´æ—¶é…ç½®ï¼Œåˆ™ç”Ÿæˆä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ä¾›ç°æœ‰æ„é€ å‡½æ•°ä½¿ç”¨
    if temp_config:
        # åˆå¹¶æ–‡ä»¶é…ç½®ï¼ˆå¦‚å­˜åœ¨ï¼‰
        file_config = {}
        if os.path.exists(args.config):
            try:
                with open(args.config, 'r', encoding='utf-8') as f:
                    file_config = yaml.safe_load(f) or {}
            except Exception:
                file_config = {}
        
        # å…¼å®¹ç®€åŒ–é”®å
        if 'links' in file_config and 'link' not in file_config:
            file_config['link'] = file_config['links']
        if 'output_dir' in file_config and 'path' not in file_config:
            file_config['path'] = file_config['output_dir']
        if 'cookie' in file_config and 'cookies' not in file_config:
            file_config['cookies'] = file_config['cookie']
        
        merged = {**(file_config or {}), **temp_config}
        with open('temp_config.yml', 'w', encoding='utf-8') as f:
            yaml.dump(merged, f, allow_unicode=True)
        config_path = 'temp_config.yml'
    else:
        config_path = args.config
    
    # è¿è¡Œä¸‹è½½å™¨
    try:
        downloader = UnifiedDownloader(config_path)
        asyncio.run(downloader.run())
    except KeyboardInterrupt:
        console.print("\n[yellow]âš ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½[/yellow]")
    except Exception as e:
        console.print(f"\n[red]âŒ ç¨‹åºå¼‚å¸¸: {e}[/red]")
        logger.exception("ç¨‹åºå¼‚å¸¸")
    finally:
        # æ¸…ç†ä¸´æ—¶é…ç½®
        if args.url and os.path.exists('temp_config.yml'):
            os.remove('temp_config.yml')


if __name__ == '__main__':
    main()